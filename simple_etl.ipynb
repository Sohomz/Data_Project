{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd\n",
    "import pyodbc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using this function as spark instance\n",
    "def spark_inst():\n",
    "    return SparkSession.builder.master(\"local[*]\").appName('Spark').getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add metadata for extract\n",
    "def metadata():\n",
    "\n",
    "    # options specific to csv where i am infering schema and making the first row the column\n",
    "    option = {\n",
    "        \"inferSchema\": \"true\",\n",
    "        \"header\": \"true\"\n",
    "    }\n",
    "    # D:\\Workspace\\Data_Project\\dataset\\titanic.csv\n",
    "    path = \"D:\\Workspace\\Data_Project\\dataset\\\\titanic.csv\"\n",
    "\n",
    "    # file type being comma seperated values\n",
    "    file_type = \"csv\"\n",
    "\n",
    "    return path, file_type, option\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract function\n",
    "def extract(spark):\n",
    "\n",
    "    path, file_type, option = metadata()\n",
    "\n",
    "    return spark.read.format(file_type).options(**option).load(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting schema :  DataFrame[PassengerId: int, Survived: int, Pclass: int, Name: string, Sex: string, Age: double, SibSp: int, Parch: int, Ticket: string, Fare: double, Cabin: string, Embarked: string]\n",
      "Getting top 5 columns : \n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Total no of passengers :  891\n",
      "No of passenger id being null :  0\n",
      "No of survived being null :  0\n",
      "No of pclass being null :  0\n",
      "No of name being null :  0\n",
      "No of sex being null :  0\n",
      "No of age being null :  177\n",
      "No of sibsp being null :  0\n",
      "No of pasenger id being null :  0\n",
      "No of ticket being null :  0\n",
      "No of fare being null :  0\n",
      "No of cabin being null :  687\n",
      "No of embarked being null :  2\n",
      "Total count of null values in Age, Cabin and Embarked:  708\n"
     ]
    }
   ],
   "source": [
    "def data_profiling(df):\n",
    "    # Getting schema\n",
    "    print(\"Getting schema : \", df)\n",
    "\n",
    "    # Getting top 5 columns\n",
    "    print(\"Getting top 5 columns : \")\n",
    "    df.show(n=5)\n",
    "\n",
    "    # Total no of passengers\n",
    "    print(\"Total no of passengers : \", df.count())\n",
    "\n",
    "    # No of passenger id being null\n",
    "    print(\"No of passenger id being null : \",\n",
    "          df.filter(\"PassengerId is NULL\").count())\n",
    "\n",
    "    # No of survived being null\n",
    "    print(\"No of survived being null : \",\n",
    "          df.filter(\"Survived is NULL\").count())\n",
    "\n",
    "    # No of pclass being null\n",
    "    print(\"No of pclass being null : \", df.filter(\"Pclass is NULL\").count())\n",
    "\n",
    "    # No of name being null\n",
    "    print(\"No of name being null : \", df.filter(\"Name is NULL\").count())\n",
    "\n",
    "    # No of sex being null\n",
    "    print(\"No of sex being null : \", df.filter(\"Sex is NULL\").count())\n",
    "\n",
    "    # No of age being null\n",
    "    print(\"No of age being null : \", df.filter(\"Age is NULL\").count())\n",
    "\n",
    "    # No of sibsp being null\n",
    "    print(\"No of sibsp being null : \", df.filter(\"SibSp is NULL\").count())\n",
    "\n",
    "    # No of parch being null\n",
    "    print(\"No of pasenger id being null : \",\n",
    "          df.filter(\"PassengerId is NULL\").count())\n",
    "\n",
    "    # No of ticket being null\n",
    "    print(\"No of ticket being null : \", df.filter(\"Ticket is NULL\").count())\n",
    "\n",
    "    # No of fare being null\n",
    "    print(\"No of fare being null : \", df.filter(\"Fare is NULL\").count())\n",
    "\n",
    "    # No of cabin being null\n",
    "    print(\"No of cabin being null : \", df.filter(\"Cabin is NULL\").count())\n",
    "\n",
    "    # No of embarked being null\n",
    "    print(\"No of embarked being null : \",\n",
    "          df.filter(\"Embarked is NULL\").count())\n",
    "\n",
    "    # Total count after removing null values\n",
    "    print(\"Total count of null values in Age, Cabin and Embarked: \", df.select(\n",
    "        \"*\").where((col(\"Age\").isNull()) | (col(\"Cabin\").isNull()) | (col(\"Embarked\").isNull())).count())\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = extract(spark_inst())\n",
    "data_profiled_data = data_profiling(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation function\n",
    "def transform(df):\n",
    "\n",
    "    df = df.filter((col(\"Age\").isNotNull()) & (\n",
    "        col(\"Cabin\").isNotNull()) & (col(\"Embarked\").isNotNull()))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "titanic_transformed = transform(data_profiled_data)\n",
    "pandasDF = titanic_transformed.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load function\n",
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=ABHIMAYNU;'\n",
    "                      'Database=titanic;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"TRUNCATE TABLE Titanic\")\n",
    "conn.commit()\n",
    "\n",
    "for index, row in pandasDF.iterrows():\n",
    "    cursor.execute(\"INSERT INTO Titanic([PassengerId],[Survived],[Pclass],[Name],[Sex],[Age],[SibSp],[Parch],[Ticket],[Fare],[Cabin],[Embarked])  values (?,?,?,?,?,?,?,?,?,?,?,?)\",\n",
    "                   row['PassengerId'], row['Survived'], row['Pclass'], row['Name'], row['Sex'], row['Age'], row['SibSp'], row['Parch'], row['Ticket'], row['Fare'], row['Cabin'], row['Embarked'])\n",
    "    conn.commit()\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "required_modules",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "60c0a7599279c7abdaab5b37799635d84a0c0076ec94c41bd9ca976b6f32ad1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
